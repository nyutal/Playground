{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chris McCormick - BERT Word Embeddings Tutorial\n",
    "http://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knight',\n",
       " 'lap',\n",
       " 'survey',\n",
       " 'ma',\n",
       " '##ow',\n",
       " 'noise',\n",
       " 'billy',\n",
       " '##ium',\n",
       " 'shooting',\n",
       " 'guide',\n",
       " 'bedroom',\n",
       " 'priest',\n",
       " 'resistance',\n",
       " 'motor',\n",
       " 'homes',\n",
       " 'sounded',\n",
       " 'giant',\n",
       " '##mer',\n",
       " '150',\n",
       " 'scenes']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "list(tokenizer.vocab.keys())[5000:5020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marked text:\n",
      "[CLS] After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank. [SEP]\n",
      "\n",
      "tokens:\n",
      "['[', 'cl', '##s', ']', 'after', 'stealing', 'money', 'from', 'the', 'bank', 'vault', ',', 'the', 'bank', 'robber', 'was', 'seen', 'fishing', 'on', 'the', 'mississippi', 'river', 'bank', '.', '[', 'sep', ']']\n",
      "\n",
      "tokens index:\n",
      "[('[', 1031), ('cl', 18856), ('##s', 2015), (']', 1033), ('after', 2044), ('stealing', 11065), ('money', 2769), ('from', 2013), ('the', 1996), ('bank', 2924), ('vault', 11632), (',', 1010), ('the', 1996), ('bank', 2924), ('robber', 27307), ('was', 2001), ('seen', 2464), ('fishing', 5645), ('on', 2006), ('the', 1996), ('mississippi', 5900), ('river', 2314), ('bank', 2924), ('.', 1012), ('[', 1031), ('sep', 19802), (']', 1033)]\n",
      "sergments: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "print('marked text:')\n",
    "print (marked_text)\n",
    "\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "print('\\ntokens:')\n",
    "print (tokenized_text)\n",
    "\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "print('\\ntokens index:')\n",
    "print([tup for tup in zip(tokenized_text, indexed_tokens)])\n",
    "\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "print('sergments:', segments_ids)\n",
    "\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407873900/407873900 [00:16<00:00, 24195266.91B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 12\n",
      "Number of batches: 1\n",
      "Number of tokens: 27\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(encoded_layers))\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the 5th token in our sentence, select its feature values from layer 5.\n",
    "batch_i = 0\n",
    "token_i = 5\n",
    "layer_i = 5\n",
    "vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in sequence: 27\n",
      "Number of layers per token: 12\n"
     ]
    }
   ],
   "source": [
    "# Convert the hidden state embeddings into single token vectors\n",
    "\n",
    "# Holds the list of 12 layer embeddings for each token\n",
    "# Will have the shape: [# tokens, # layers, # features]\n",
    "token_embeddings = [] \n",
    "\n",
    "# For each token in the sentence...\n",
    "for token_i in range(len(tokenized_text)):\n",
    "  \n",
    "  # Holds 12 layers of hidden states for each token \n",
    "  hidden_layers = [] \n",
    "  \n",
    "  # For each of the 12 layers...\n",
    "  for layer_i in range(len(encoded_layers)):\n",
    "    \n",
    "    # Lookup the vector for `token_i` in `layer_i`\n",
    "    vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "    \n",
    "    hidden_layers.append(vec)\n",
    "    \n",
    "  token_embeddings.append(hidden_layers)\n",
    "\n",
    "# Sanity check the dimensions:\n",
    "print (\"Number of tokens in sequence:\", len(token_embeddings))\n",
    "print (\"Number of layers per token:\", len(token_embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word vectors example:\n",
    "concatenated_last_4_layers = [torch.cat((layer[-1], layer[-2], layer[-3], layer[-4]), 0) for layer in token_embeddings] # [number_of_tokens, 3072]\n",
    "summed_last_4_layers = [torch.sum(torch.stack(layer)[-4:], 0) for layer in token_embeddings] # [number_of_tokens, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final sentence embedding vector of shape:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 768)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence embedding example:\n",
    "sentence_embedding = torch.mean(encoded_layers[11], 1)\n",
    "print (\"Our final sentence embedding vector of shape:\"), sentence_embedding[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
